{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e282fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from os import path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error  \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold  \n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d30937",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/end_every_end.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 排除第一列\n",
    "columns_to_normalize = data.columns.tolist()\n",
    "columns_to_normalize.remove(data.columns[0])\n",
    "\n",
    "# 创建一个MinMaxScaler对象\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 对选定的列进行归一化\n",
    "data[columns_to_normalize] = scaler.fit_transform(data[columns_to_normalize])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4dfd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "\n",
    "X = df.values[1:, 1:-1].astype(float)\n",
    "# for train_index, test_index in kf.split(x_train_real):\n",
    "#     x_train, x_test = x_train_real[train_index], x_test_real[test_index]\n",
    "#     y_test = y_test_real[test_index]\n",
    "#     x_train = torch.from_numpy(x_train).float()\n",
    "#     x_test = torch.from_numpy(x_test).float()\n",
    "y = df.values[1:, -1].astype(float)\n",
    "\n",
    "# 对数据进行标准化处理  \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 划分训练集和测试集  \n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1217b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 孤立森林\n",
    "from sklearn.ensemble import IsolationForest\n",
    "isolation_forest = IsolationForest(n_estimators=120, max_samples=64, contamination=0.07, random_state=42)\n",
    "isolation_forest.fit(X_train)\n",
    "\n",
    "y_pred = isolation_forest.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)  \n",
    "print('MSE:', mse)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "recall = metrics.recall_score(y_test, y_pred, average='macro')\n",
    "precision = metrics.precision_score(y_test, y_pred, average='macro')\n",
    "f1 = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
